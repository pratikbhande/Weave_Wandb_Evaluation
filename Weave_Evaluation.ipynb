{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "Agb_RyQk7X_A",
        "outputId": "cd638daa-39f3-4ba1-ac09-8646fb572570"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting weave\n",
            "  Downloading weave-0.51.25-py3-none-any.whl.metadata (21 kB)\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (1.57.4)\n",
            "Collecting emoji>=2.12.1 (from weave)\n",
            "  Downloading emoji-2.14.0-py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting gql[aiohttp,requests] (from weave)\n",
            "  Downloading gql-3.5.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: jsonschema>=4.23.0 in /usr/local/lib/python3.10/dist-packages (from weave) (4.23.0)\n",
            "Requirement already satisfied: numpy>1.21.0 in /usr/local/lib/python3.10/dist-packages (from weave) (1.26.4)\n",
            "Requirement already satisfied: packaging>=21.0 in /usr/local/lib/python3.10/dist-packages (from weave) (24.2)\n",
            "Requirement already satisfied: pydantic>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from weave) (2.10.3)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from weave) (13.9.4)\n",
            "Requirement already satisfied: tenacity!=8.4.0,>=8.3.0 in /usr/local/lib/python3.10/dist-packages (from weave) (9.0.0)\n",
            "Collecting uuid-utils>=0.9.0 (from weave)\n",
            "  Downloading uuid_utils-0.10.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: wandb>=0.17.1 in /usr/local/lib/python3.10/dist-packages (from weave) (0.19.1)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.8.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.10/dist-packages (from openai) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.12.14)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=4.23.0->weave) (24.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=4.23.0->weave) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=4.23.0->weave) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=4.23.0->weave) (0.22.3)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0.0->weave) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.1 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0.0->weave) (2.27.1)\n",
            "Requirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb>=0.17.1->weave) (8.1.7)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from wandb>=0.17.1->weave) (0.4.0)\n",
            "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb>=0.17.1->weave) (3.1.43)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.10/dist-packages (from wandb>=0.17.1->weave) (4.3.6)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<6,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb>=0.17.1->weave) (4.25.5)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb>=0.17.1->weave) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from wandb>=0.17.1->weave) (6.0.2)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb>=0.17.1->weave) (2.32.3)\n",
            "Requirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb>=0.17.1->weave) (2.19.2)\n",
            "Requirement already satisfied: setproctitle in /usr/local/lib/python3.10/dist-packages (from wandb>=0.17.1->weave) (1.3.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb>=0.17.1->weave) (75.1.0)\n",
            "Collecting graphql-core<3.3,>=3.2 (from gql[aiohttp,requests]->weave)\n",
            "  Downloading graphql_core-3.2.5-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: yarl<2.0,>=1.6 in /usr/local/lib/python3.10/dist-packages (from gql[aiohttp,requests]->weave) (1.18.3)\n",
            "Collecting backoff<3.0,>=1.11.1 (from gql[aiohttp,requests]->weave)\n",
            "  Downloading backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: aiohttp<4,>=3.8.0 in /usr/local/lib/python3.10/dist-packages (from gql[aiohttp,requests]->weave) (3.11.10)\n",
            "Requirement already satisfied: requests-toolbelt<2,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from gql[aiohttp,requests]->weave) (1.0.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->weave) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->weave) (2.18.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4,>=3.8.0->gql[aiohttp,requests]->weave) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4,>=3.8.0->gql[aiohttp,requests]->weave) (1.3.2)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4,>=3.8.0->gql[aiohttp,requests]->weave) (4.0.3)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4,>=3.8.0->gql[aiohttp,requests]->weave) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4,>=3.8.0->gql[aiohttp,requests]->weave) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4,>=3.8.0->gql[aiohttp,requests]->weave) (0.2.1)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb>=0.17.1->weave) (1.17.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb>=0.17.1->weave) (4.0.11)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->weave) (0.1.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb>=0.17.1->weave) (3.4.0)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb>=0.17.1->weave) (2.2.3)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb>=0.17.1->weave) (5.0.1)\n",
            "Downloading weave-0.51.25-py3-none-any.whl (328 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m328.4/328.4 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading emoji-2.14.0-py3-none-any.whl (586 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m586.9/586.9 kB\u001b[0m \u001b[31m26.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading uuid_utils-0.10.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (325 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m325.8/325.8 kB\u001b[0m \u001b[31m20.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
            "Downloading graphql_core-3.2.5-py3-none-any.whl (203 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m203.2/203.2 kB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gql-3.5.0-py2.py3-none-any.whl (74 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m74.0/74.0 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: uuid-utils, graphql-core, emoji, backoff, gql, weave\n",
            "Successfully installed backoff-2.2.1 emoji-2.14.0 gql-3.5.0 graphql-core-3.2.5 uuid-utils-0.10.0 weave-0.51.25\n"
          ]
        }
      ],
      "source": [
        "!pip install weave openai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import weave\n",
        "\n",
        "weave.init(\"rag-baselining\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        },
        "id": "0uDnFTkl7bF_",
        "outputId": "caa0385e-038d-4aea-d9ff-2ad38d654cf5"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Please login to Weights & Biases (https://wandb.ai/) to continue:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "wandb: Paste an API key from your profile and hit enter, or press ctrl+c to quit:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " ¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logged in as Weights & Biases user: pratikbhande0.\n",
            "View Weave data at https://wandb.ai/pratikbhande0-personal/rag-baselining/weave\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<weave.trace.weave_client.WeaveClient at 0x7da7728561a0>"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = userdata.get(\"OPENAI_API_KEY\")"
      ],
      "metadata": {
        "id": "uiXM2krm7e0O"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "\n",
        "client = OpenAI()\n",
        "response = client.chat.completions.create(\n",
        "    model=\"gpt-4o-mini\",\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": \"Translate English to Hindi.\"},\n",
        "        {\"role\": \"user\", \"content\": \"What is ML?.\"},\n",
        "    ],\n",
        "    temperature=0,\n",
        ")\n",
        "\n",
        "\n",
        "generation = response.choices[0].message.content\n",
        "print(generation)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R4sSOvFF722D",
        "outputId": "6e84a433-8684-4bcb-86f2-2ca36f58447f"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üç© https://wandb.ai/pratikbhande0-personal/rag-baselining/r/call/019416f2-ee82-7d11-bea3-48ae874a5929\n",
            "ML ‡§ï‡§æ ‡§Æ‡§§‡§≤‡§¨ ‡§Æ‡§∂‡•Ä‡§® ‡§≤‡§∞‡•ç‡§®‡§ø‡§Ç‡§ó (Machine Learning) ‡§π‡•à‡•§ ‡§Ø‡§π ‡§è‡§ï ‡§™‡•ç‡§∞‡§ï‡§æ‡§∞ ‡§ï‡•Ä ‡§Ü‡§∞‡•ç‡§ü‡§ø‡§´‡§ø‡§∂‡§ø‡§Ø‡§≤ ‡§á‡§Ç‡§ü‡•á‡§≤‡§ø‡§ú‡•á‡§Ç‡§∏ (Artificial Intelligence) ‡§π‡•à, ‡§ú‡§ø‡§∏‡§Æ‡•á‡§Ç ‡§ï‡§Ç‡§™‡•ç‡§Ø‡•Ç‡§ü‡§∞ ‡§∏‡§ø‡§∏‡•ç‡§ü‡§Æ ‡§°‡•á‡§ü‡§æ ‡§∏‡•á ‡§∏‡•Ä‡§ñ‡§§‡•á ‡§π‡•à‡§Ç ‡§î‡§∞ ‡§Ö‡§®‡•Å‡§≠‡§µ ‡§ï‡•á ‡§Ü‡§ß‡§æ‡§∞ ‡§™‡§∞ ‡§Ö‡§™‡§®‡•á ‡§™‡•ç‡§∞‡§¶‡§∞‡•ç‡§∂‡§® ‡§Æ‡•á‡§Ç ‡§∏‡•Å‡§ß‡§æ‡§∞ ‡§ï‡§∞‡§§‡•á ‡§π‡•à‡§Ç, ‡§¨‡§ø‡§®‡§æ ‡§ï‡§ø‡§∏‡•Ä ‡§µ‡§ø‡§∂‡•á‡§∑ ‡§™‡•ç‡§∞‡•ã‡§ó‡•ç‡§∞‡§æ‡§Æ‡§ø‡§Ç‡§ó ‡§ï‡•á‡•§ ‡§Æ‡§∂‡•Ä‡§® ‡§≤‡§∞‡•ç‡§®‡§ø‡§Ç‡§ó ‡§ï‡§æ ‡§â‡§™‡§Ø‡•ã‡§ó ‡§µ‡§ø‡§≠‡§ø‡§®‡•ç‡§® ‡§ï‡•ç‡§∑‡•á‡§§‡•ç‡§∞‡•ã‡§Ç ‡§Æ‡•á‡§Ç ‡§ï‡§ø‡§Ø‡§æ ‡§ú‡§æ‡§§‡§æ ‡§π‡•à, ‡§ú‡•à‡§∏‡•á ‡§ï‡§ø ‡§°‡•á‡§ü‡§æ ‡§è‡§®‡§æ‡§≤‡§ø‡§∏‡§ø‡§∏, ‡§õ‡§µ‡§ø ‡§™‡§π‡§ö‡§æ‡§®, ‡§™‡•ç‡§∞‡§æ‡§ï‡•É‡§§‡§ø‡§ï ‡§≠‡§æ‡§∑‡§æ ‡§™‡•ç‡§∞‡§∏‡§Ç‡§∏‡•ç‡§ï‡§∞‡§£, ‡§î‡§∞ ‡§¨‡§π‡•Å‡§§ ‡§ï‡•Å‡§õ‡•§\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "@weave.op()\n",
        "def translation(user_input):\n",
        "    client = OpenAI()\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"gpt-4o-mini\",\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": \"Please translate English into Hindi.\"},\n",
        "            {\"role\": \"user\", \"content\": user_input},\n",
        "        ],\n",
        "        temperature=0,\n",
        "    )\n",
        "    return response.choices[0].message.content\n",
        "\n",
        "result = translation(\"AI is a old technology\")\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ti5BfJ8e8BHA",
        "outputId": "52d0f35f-521f-4c3a-8c3c-407333551790"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üç© https://wandb.ai/pratikbhande0-personal/rag-baselining/r/call/019416f3-361f-7c20-ab53-aa5dd4cef3b4\n",
            "‡§è‡§Ü‡§à ‡§è‡§ï ‡§™‡•Å‡§∞‡§æ‡§®‡•Ä ‡§§‡§ï‡§®‡•Ä‡§ï ‡§π‡•à‡•§\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "\n",
        "class TranslationModel(weave.Model):\n",
        "    system_instruction: str\n",
        "\n",
        "    @weave.op()\n",
        "    def translation(self, user_input):\n",
        "        client = OpenAI()\n",
        "        response = client.chat.completions.create(\n",
        "            model=\"gpt-4o-mini\",\n",
        "            messages=[\n",
        "                {\"role\": \"system\", \"content\": self.system_instruction},\n",
        "                {\"role\": \"user\", \"content\": user_input},\n",
        "            ],\n",
        "            temperature=0,\n",
        "        )\n",
        "        return response.choices[0].message.content\n",
        "\n",
        "\n",
        "model = TranslationModel(\n",
        "    system_instruction=\"Please translate English into Hindi.\",\n",
        ")\n",
        "result = model.translation(\"Generative AI has been hyped up a lot.\")\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HGgA3dfc8zeJ",
        "outputId": "256df4e5-e13e-4565-b966-bac19f8774da"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üç© https://wandb.ai/pratikbhande0-personal/rag-baselining/r/call/019416f3-73d2-7102-b8f7-bb116205e85a\n",
            "‡§ú‡§®‡§∞‡•á‡§ü‡§ø‡§µ ‡§è‡§Ü‡§à ‡§ï‡•ã ‡§¨‡§π‡•Å‡§§ ‡§Ö‡§ß‡§ø‡§ï ‡§™‡•ç‡§∞‡§ö‡§æ‡§∞‡§ø‡§§ ‡§ï‡§ø‡§Ø‡§æ ‡§ó‡§Ø‡§æ ‡§π‡•à‡•§\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "documents = [\n",
        "    \"SpaceX is a private aerospace manufacturer and space transportation company founded by Elon Musk. It has revolutionized the space industry with reusable rockets and aims to enable human life on Mars.\",\n",
        "    \"NASA is the United States government agency responsible for space exploration and research. It has led historic missions like the Apollo moon landings and is currently involved in developing technologies for future space missions.\",\n",
        "    \"Tesla is a leading electric vehicle and clean energy company that focuses on accelerating the transition to sustainable energy. Its innovations include electric cars, solar panels, and energy storage solutions.\",\n",
        "    \"Blue Origin is an aerospace company founded by Jeff Bezos, aiming to make space travel more affordable and accessible. It is known for its suborbital space tourism program and development of reusable rockets.\",\n",
        "    \"Boeing is a major American corporation in the aerospace industry, manufacturing commercial airplanes, defense systems, and satellites. Boeing has a long history of contributions to aviation and space exploration.\",\n",
        "    \"Virgin Galactic is a space tourism company founded by Richard Branson. It focuses on providing commercial suborbital spaceflights for passengers, aiming to make space travel accessible to more people.\"\n",
        "]"
      ],
      "metadata": {
        "id": "36kYmfnO83UZ"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "\n",
        "\n",
        "def docs_to_embeddings(docs: list) -> list:\n",
        "    openai = OpenAI()\n",
        "    document_embeddings = []\n",
        "    for doc in docs:\n",
        "        response = (\n",
        "            openai.embeddings.create(\n",
        "                input=doc,\n",
        "                model=\"text-embedding-3-small\"\n",
        "            )\n",
        "            .data[0]\n",
        "            .embedding\n",
        "        )\n",
        "        document_embeddings.append(response)\n",
        "    return document_embeddings\n",
        "\n",
        "\n",
        "docs_embeddings = docs_to_embeddings(documents)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KpY6GBsH86YT",
        "outputId": "2b7ff50a-cb94-4f22-8319-8a7953054055"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üç© https://wandb.ai/pratikbhande0-personal/rag-baselining/r/call/019416f3-da95-7b40-b1a6-99300384b295\n",
            "üç© https://wandb.ai/pratikbhande0-personal/rag-baselining/r/call/019416f3-dcee-7c73-92e3-47a1c69fdda3\n",
            "üç© https://wandb.ai/pratikbhande0-personal/rag-baselining/r/call/019416f3-ddc5-7331-8d10-d37daae5e48f\n",
            "üç© https://wandb.ai/pratikbhande0-personal/rag-baselining/r/call/019416f3-de95-7b62-9399-bc24b7b8a3bc\n",
            "üç© https://wandb.ai/pratikbhande0-personal/rag-baselining/r/call/019416f3-dfef-7ec2-9502-26be2a07149d\n",
            "üç© https://wandb.ai/pratikbhande0-personal/rag-baselining/r/call/019416f3-e0e6-74c3-9a0c-2de645d1bd69\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "\n",
        "@weave.op()\n",
        "def get_most_relevant_document(query):\n",
        "\n",
        "    openai = OpenAI()\n",
        "    query_embedding = (\n",
        "        openai.embeddings.create(\n",
        "            input=query,\n",
        "            model=\"text-embedding-3-small\"\n",
        "        )\n",
        "        .data[0]\n",
        "        .embedding\n",
        "    )\n",
        "\n",
        "\n",
        "    similarities = [\n",
        "        np.dot(query_embedding, doc_emb)\n",
        "        / (np.linalg.norm(query_embedding) * np.linalg.norm(doc_emb))\n",
        "        for doc_emb in docs_embeddings\n",
        "    ]\n",
        "\n",
        "\n",
        "    most_relevant_doc_index = np.argmax(similarities)\n",
        "    return documents[most_relevant_doc_index]"
      ],
      "metadata": {
        "id": "xMvVYYBh89tn"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class RAGModel(weave.Model):\n",
        "    model_name: str = \"gpt-4o\"\n",
        "\n",
        "\n",
        "    @weave.op()\n",
        "    def predict(self, question: str) -> dict:\n",
        "\n",
        "        context = get_most_relevant_document(question)\n",
        "\n",
        "\n",
        "        client = OpenAI()\n",
        "        query = f\"\"\"Please answer the questions using only the following context.\n",
        "If you don't know the answer, answer 'I don't know.'\n",
        "\n",
        "\n",
        "context:\"\n",
        "```\n",
        "{context}\n",
        "```\n",
        "\n",
        "question:\n",
        "{question}\"\"\"\n",
        "        response = client.chat.completions.create(\n",
        "            model=self.model_name,\n",
        "            messages=[\n",
        "                {\"role\": \"user\", \"content\": query},\n",
        "            ],\n",
        "            temperature=0.0,\n",
        "            response_format={\"type\": \"text\"},\n",
        "        )\n",
        "        answer = response.choices[0].message.content\n",
        "        return {\"answer\": answer, \"context\": context}"
      ],
      "metadata": {
        "id": "SiC2VWDW9Hp4"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = RAGModel(\n",
        "    model_name=\"gpt-4o\"\n",
        ")\n",
        "model.predict(\"What is NASA?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bj4Hlc599LSU",
        "outputId": "cce4d215-6327-4294-f176-bd2581c4370e"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üç© https://wandb.ai/pratikbhande0-personal/rag-baselining/r/call/019416f4-d21c-7311-863f-9fbf1229fef9\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'answer': 'NASA is the United States government agency responsible for space exploration and research.',\n",
              " 'context': 'NASA is the United States government agency responsible for space exploration and research. It has led historic missions like the Apollo moon landings and is currently involved in developing technologies for future space missions.'}"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "questions = [\n",
        "    {\"question\": \"Who founded SpaceX?\"},\n",
        "    {\"question\": \"Which U.S. government agency is responsible for space exploration?\"},\n",
        "    {\"question\": \"What company is focused on accelerating the transition to sustainable energy?\"},\n",
        "    {\"question\": \"Which company aims to make space travel more affordable and accessible?\"},\n",
        "    {\"question\": \"Which major American corporation is involved in both aviation and space exploration?\"},\n",
        "    {\"question\": \"What company is focused on commercial space tourism?\"}\n",
        "]"
      ],
      "metadata": {
        "id": "OWU3uAgy9NN0"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "@weave.op()\n",
        "async def context_precision_score(question, model_output):\n",
        "    context_precision_prompt = \"\"\"Given the question, answer, and context, verify whether the context helped in reaching the provided answer.\n",
        "In the JSON output, if the context was useful, output {{verification: 1}}.\n",
        "If the context was not useful, output {{verification: 0}}.\n",
        "Output in valid JSON format only.\n",
        "\n",
        "Context:\n",
        "```\n",
        "{context}\n",
        "```\n",
        "\n",
        "Answer:\n",
        "{answer}\n",
        "\"\"\"\n",
        "\n",
        "    client = OpenAI()\n",
        "    prompt = context_precision_prompt.format(\n",
        "        question=question,\n",
        "        context=model_output[\"context\"],\n",
        "        answer=model_output[\"answer\"],\n",
        "    )\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"gpt-4o\",\n",
        "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "        response_format={ \"type\": \"json_object\" }\n",
        "    )\n",
        "    response_message = response.choices[0].message\n",
        "    response = json.loads(response_message.content)\n",
        "    return {\n",
        "        \"verdict\": int(response[\"verification\"]) == 1,\n",
        "    }"
      ],
      "metadata": {
        "id": "FpIBeN289Pr_"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nest_asyncio\n",
        "nest_asyncio.apply()"
      ],
      "metadata": {
        "id": "MzoEPR9Y9SWn"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evaluation = weave.Evaluation(\n",
        "    dataset=questions,\n",
        "    scorers=[context_precision_score]\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cp9M0a0B9VBw",
        "outputId": "c3a84b1c-6755-4e11-8eb7-dd99f000ebfd"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:weave.flow.eval:Using 'model_output' key for compatibility with older scorers. Please update scorers to use 'output' parameter.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = RAGModel(\n",
        "    model_name=\"gpt-4o\"\n",
        ")\n",
        "await evaluation.evaluate(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 262
        },
        "id": "Ctly1LF49XD0",
        "outputId": "dba3d8c2-40f1-490f-9df1-cffa819fc04e"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m1\u001b[0m of \u001b[1;36m6\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m2\u001b[0m of \u001b[1;36m6\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m3\u001b[0m of \u001b[1;36m6\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m4\u001b[0m of \u001b[1;36m6\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m5\u001b[0m of \u001b[1;36m6\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m6\u001b[0m of \u001b[1;36m6\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluation summary\n",
              "\u001b[1m{\u001b[0m\n",
              "    \u001b[32m'context_precision_score'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'verdict'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'true_count'\u001b[0m: \u001b[1;36m5\u001b[0m, \u001b[32m'true_fraction'\u001b[0m: \u001b[1;36m0.8333333333333334\u001b[0m\u001b[1m}\u001b[0m\u001b[1m}\u001b[0m,\n",
              "    \u001b[32m'model_latency'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'mean'\u001b[0m: \u001b[1;36m5.697587490081787\u001b[0m\u001b[1m}\u001b[0m\n",
              "\u001b[1m}\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluation summary\n",
              "<span style=\"font-weight: bold\">{</span>\n",
              "    <span style=\"color: #008000; text-decoration-color: #008000\">'context_precision_score'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'verdict'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'true_count'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'true_fraction'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.8333333333333334</span><span style=\"font-weight: bold\">}}</span>,\n",
              "    <span style=\"color: #008000; text-decoration-color: #008000\">'model_latency'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'mean'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5.697587490081787</span><span style=\"font-weight: bold\">}</span>\n",
              "<span style=\"font-weight: bold\">}</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üç© https://wandb.ai/pratikbhande0-personal/rag-baselining/r/call/019416f5-9094-70a3-a39a-7da0cd49e05b\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'context_precision_score': {'verdict': {'true_count': 5,\n",
              "   'true_fraction': 0.8333333333333334}},\n",
              " 'model_latency': {'mean': 5.697587490081787}}"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = RAGModel(\n",
        "    model_name=\"gpt-4o-mini\"\n",
        ")\n",
        "await evaluation.evaluate(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 262
        },
        "id": "ECwCoEur9ZG4",
        "outputId": "7e22fb0b-3931-4299-c8f3-9f1147acd56c"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m1\u001b[0m of \u001b[1;36m6\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m2\u001b[0m of \u001b[1;36m6\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m3\u001b[0m of \u001b[1;36m6\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m4\u001b[0m of \u001b[1;36m6\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m5\u001b[0m of \u001b[1;36m6\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m6\u001b[0m of \u001b[1;36m6\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluation summary\n",
              "\u001b[1m{\u001b[0m\n",
              "    \u001b[32m'context_precision_score'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'verdict'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'true_count'\u001b[0m: \u001b[1;36m6\u001b[0m, \u001b[32m'true_fraction'\u001b[0m: \u001b[1;36m1.0\u001b[0m\u001b[1m}\u001b[0m\u001b[1m}\u001b[0m,\n",
              "    \u001b[32m'model_latency'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'mean'\u001b[0m: \u001b[1;36m5.078067262967427\u001b[0m\u001b[1m}\u001b[0m\n",
              "\u001b[1m}\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluation summary\n",
              "<span style=\"font-weight: bold\">{</span>\n",
              "    <span style=\"color: #008000; text-decoration-color: #008000\">'context_precision_score'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'verdict'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'true_count'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'true_fraction'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.0</span><span style=\"font-weight: bold\">}}</span>,\n",
              "    <span style=\"color: #008000; text-decoration-color: #008000\">'model_latency'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'mean'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5.078067262967427</span><span style=\"font-weight: bold\">}</span>\n",
              "<span style=\"font-weight: bold\">}</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üç© https://wandb.ai/pratikbhande0-personal/rag-baselining/r/call/019416f5-dd09-7571-bed5-ab0f7520082f\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'context_precision_score': {'verdict': {'true_count': 6,\n",
              "   'true_fraction': 1.0}},\n",
              " 'model_latency': {'mean': 5.078067262967427}}"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "q1x6_aH69d5k"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}